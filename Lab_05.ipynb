{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries"
      ],
      "metadata": {
        "id": "KqawMSMatWXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NLmLWqNxs0z-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # data handling (DataFrames)\n",
        "import numpy as np  # numerical operations\n",
        "from sklearn.model_selection import train_test_split  # split dataset into train & test sets\n",
        "from sklearn.preprocessing import StandardScaler  # feature scaling/normalization\n",
        "from sklearn.metrics import mean_squared_error  # evaluate regression models\n",
        "import tensorflow as tf  # deep learning library\n",
        "from tensorflow import keras  # build neural network models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part A"
      ],
      "metadata": {
        "id": "Mjl94SIKtak_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "KGVx7CvvtmUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"diabetes.csv\")  # load dataset from CSV file into a pandas DataFrame\n",
        "X = data.iloc[:, :8].values  # select first 8 columns as features (independent variables)\n",
        "y = data.iloc[:, 8].values   # select 9th column as target (dependent variable)"
      ],
      "metadata": {
        "id": "RZPOyR2vtZzM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and testing data"
      ],
      "metadata": {
        "id": "HjQcBDrgt-Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=0, stratify=y)  # split data into 80% train & 20% test, keeping class distribution balanced"
      ],
      "metadata": {
        "id": "LYktp-u1t_C2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardizing"
      ],
      "metadata": {
        "id": "m9EgTMPtuEog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()  # create StandardScaler object for feature normalization (zero mean, unit variance)\n",
        "X_train = scaler.fit_transform(X_train)  # fit scaler on training data & apply scaling\n",
        "X_test = scaler.transform(X_test)  # apply same scaling parameters to test data (no refit to avoid data leakage)"
      ],
      "metadata": {
        "id": "d4fxsCLHuF-m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture (Dropout)"
      ],
      "metadata": {
        "id": "gQkSJj47uLL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),  # input layer with number of features as input shape\n",
        "    keras.layers.Dense(5, activation=\"relu\"),  # hidden layer with 5 neurons, ReLU activation\n",
        "    keras.layers.Dropout(0.3),  # dropout layer (30% neurons randomly dropped to prevent overfitting)\n",
        "    keras.layers.Dense(3, activation=\"relu\"),  # hidden layer with 3 neurons, ReLU activation\n",
        "    keras.layers.Dropout(0.2),  # dropout layer (20% neurons randomly dropped)\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")  # output layer (1 neuron, sigmoid for binary classification)\n",
        "])"
      ],
      "metadata": {
        "id": "IgoQRRgNuOJn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture (Batch Normalization)"
      ],
      "metadata": {
        "id": "-SoVcSAvuRz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization  # import BatchNormalization layer\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),  # input layer with feature size\n",
        "    keras.layers.Dense(5, activation=\"relu\"),  # hidden layer with 5 neurons, ReLU activation\n",
        "    BatchNormalization(),  # normalize outputs of previous layer (helps stability & faster training)\n",
        "    keras.layers.Dense(3, activation=\"relu\"),  # hidden layer with 3 neurons, ReLU activation\n",
        "    BatchNormalization(),  # normalize outputs of this hidden layer\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")  # output layer for binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "sngkP-zQuS9_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "kEhQ2CScuWYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",  # Adam optimizer (adaptive learning rate)\n",
        "    loss=\"binary_crossentropy\",  # loss function for binary classification\n",
        "    metrics=[\"accuracy\"]  # track accuracy during training/testing\n",
        ")"
      ],
      "metadata": {
        "id": "XcQfVkajuYtR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "Y5WjSAW6ufgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,        # training data (features and labels)\n",
        "    epochs=100,              # number of times the model sees the whole dataset\n",
        "    batch_size=32,           # number of samples per gradient update\n",
        "    validation_split=0.2,    # use 20% of training data for validation\n",
        "    verbose=1                # show progress output during training\n",
        ")"
      ],
      "metadata": {
        "id": "qwkcD1jHug9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c2bc23-267f-46a1-c6dd-46b33c680090"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6316 - loss: 0.7161 - val_accuracy: 0.4878 - val_loss: 0.6964\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.7352 - val_accuracy: 0.4878 - val_loss: 0.6957\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5844 - loss: 0.7713 - val_accuracy: 0.5041 - val_loss: 0.6921\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6363 - loss: 0.6888 - val_accuracy: 0.5366 - val_loss: 0.6876\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6477 - loss: 0.6657 - val_accuracy: 0.5691 - val_loss: 0.6825\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6477 - loss: 0.6671 - val_accuracy: 0.5854 - val_loss: 0.6787\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6581 - loss: 0.6690 - val_accuracy: 0.5935 - val_loss: 0.6740\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6569 - loss: 0.6613 - val_accuracy: 0.6179 - val_loss: 0.6685\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6419 - loss: 0.6494 - val_accuracy: 0.6179 - val_loss: 0.6646\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7079 - loss: 0.5999 - val_accuracy: 0.6179 - val_loss: 0.6617\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7039 - loss: 0.6191 - val_accuracy: 0.6179 - val_loss: 0.6592\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7399 - loss: 0.5726 - val_accuracy: 0.6179 - val_loss: 0.6558\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6838 - loss: 0.6046 - val_accuracy: 0.6260 - val_loss: 0.6525\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7223 - loss: 0.5942 - val_accuracy: 0.6260 - val_loss: 0.6483\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7071 - loss: 0.5894 - val_accuracy: 0.6260 - val_loss: 0.6447\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7189 - loss: 0.5674 - val_accuracy: 0.6260 - val_loss: 0.6401\n",
            "Epoch 17/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7229 - loss: 0.5451 - val_accuracy: 0.6260 - val_loss: 0.6367\n",
            "Epoch 18/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7109 - loss: 0.5739 - val_accuracy: 0.6341 - val_loss: 0.6331\n",
            "Epoch 19/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7071 - loss: 0.5690 - val_accuracy: 0.6667 - val_loss: 0.6306\n",
            "Epoch 20/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6935 - loss: 0.5722 - val_accuracy: 0.6667 - val_loss: 0.6265\n",
            "Epoch 21/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7287 - loss: 0.5306 - val_accuracy: 0.6667 - val_loss: 0.6246\n",
            "Epoch 22/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7243 - loss: 0.5559 - val_accuracy: 0.6423 - val_loss: 0.6215\n",
            "Epoch 23/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7204 - loss: 0.5537 - val_accuracy: 0.6585 - val_loss: 0.6184\n",
            "Epoch 24/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7669 - loss: 0.5307 - val_accuracy: 0.6423 - val_loss: 0.6170\n",
            "Epoch 25/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.5119 - val_accuracy: 0.6504 - val_loss: 0.6164\n",
            "Epoch 26/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7206 - loss: 0.5334 - val_accuracy: 0.6667 - val_loss: 0.6128\n",
            "Epoch 27/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7481 - loss: 0.4971 - val_accuracy: 0.6748 - val_loss: 0.6106\n",
            "Epoch 28/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7417 - loss: 0.5142 - val_accuracy: 0.6748 - val_loss: 0.6079\n",
            "Epoch 29/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 0.5014 - val_accuracy: 0.6748 - val_loss: 0.6047\n",
            "Epoch 30/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.4761 - val_accuracy: 0.6667 - val_loss: 0.6042\n",
            "Epoch 31/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7187 - loss: 0.5231 - val_accuracy: 0.6667 - val_loss: 0.6018\n",
            "Epoch 32/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.4941 - val_accuracy: 0.6829 - val_loss: 0.6005\n",
            "Epoch 33/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7223 - loss: 0.5145 - val_accuracy: 0.6992 - val_loss: 0.5976\n",
            "Epoch 34/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7456 - loss: 0.4883 - val_accuracy: 0.7073 - val_loss: 0.5952\n",
            "Epoch 35/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7601 - loss: 0.4782 - val_accuracy: 0.7073 - val_loss: 0.5930\n",
            "Epoch 36/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7559 - loss: 0.4721 - val_accuracy: 0.7317 - val_loss: 0.5913\n",
            "Epoch 37/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.5118 - val_accuracy: 0.7317 - val_loss: 0.5891\n",
            "Epoch 38/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7475 - loss: 0.4730 - val_accuracy: 0.7317 - val_loss: 0.5885\n",
            "Epoch 39/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7421 - loss: 0.5156 - val_accuracy: 0.7398 - val_loss: 0.5878\n",
            "Epoch 40/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.4851 - val_accuracy: 0.7317 - val_loss: 0.5873\n",
            "Epoch 41/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7481 - loss: 0.4985 - val_accuracy: 0.7317 - val_loss: 0.5850\n",
            "Epoch 42/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7631 - loss: 0.4849 - val_accuracy: 0.7317 - val_loss: 0.5851\n",
            "Epoch 43/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.4724 - val_accuracy: 0.7317 - val_loss: 0.5846\n",
            "Epoch 44/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.4799 - val_accuracy: 0.7236 - val_loss: 0.5831\n",
            "Epoch 45/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7825 - loss: 0.4617 - val_accuracy: 0.7236 - val_loss: 0.5825\n",
            "Epoch 46/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 0.4774 - val_accuracy: 0.7236 - val_loss: 0.5829\n",
            "Epoch 47/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.4533 - val_accuracy: 0.7236 - val_loss: 0.5832\n",
            "Epoch 48/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7128 - loss: 0.5439 - val_accuracy: 0.7236 - val_loss: 0.5825\n",
            "Epoch 49/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7372 - loss: 0.5045 - val_accuracy: 0.7236 - val_loss: 0.5817\n",
            "Epoch 50/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7787 - loss: 0.4682 - val_accuracy: 0.7236 - val_loss: 0.5813\n",
            "Epoch 51/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7708 - loss: 0.4708 - val_accuracy: 0.7236 - val_loss: 0.5799\n",
            "Epoch 52/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7799 - loss: 0.4577 - val_accuracy: 0.7236 - val_loss: 0.5792\n",
            "Epoch 53/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7743 - loss: 0.4591 - val_accuracy: 0.7317 - val_loss: 0.5790\n",
            "Epoch 54/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7730 - loss: 0.4795 - val_accuracy: 0.7317 - val_loss: 0.5791\n",
            "Epoch 55/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7682 - loss: 0.4797 - val_accuracy: 0.7236 - val_loss: 0.5788\n",
            "Epoch 56/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7705 - loss: 0.4822 - val_accuracy: 0.7317 - val_loss: 0.5774\n",
            "Epoch 57/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7636 - loss: 0.4462 - val_accuracy: 0.7398 - val_loss: 0.5757\n",
            "Epoch 58/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7696 - loss: 0.4868 - val_accuracy: 0.7317 - val_loss: 0.5742\n",
            "Epoch 59/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7958 - loss: 0.4448 - val_accuracy: 0.7317 - val_loss: 0.5743\n",
            "Epoch 60/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7795 - loss: 0.4520 - val_accuracy: 0.7236 - val_loss: 0.5742\n",
            "Epoch 61/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7984 - loss: 0.4363 - val_accuracy: 0.7317 - val_loss: 0.5751\n",
            "Epoch 62/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7498 - loss: 0.4549 - val_accuracy: 0.7236 - val_loss: 0.5752\n",
            "Epoch 63/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7841 - loss: 0.4616 - val_accuracy: 0.7317 - val_loss: 0.5741\n",
            "Epoch 64/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7508 - loss: 0.4680 - val_accuracy: 0.7398 - val_loss: 0.5743\n",
            "Epoch 65/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7782 - loss: 0.4818 - val_accuracy: 0.7398 - val_loss: 0.5746\n",
            "Epoch 66/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7591 - loss: 0.4990 - val_accuracy: 0.7398 - val_loss: 0.5742\n",
            "Epoch 67/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.4568 - val_accuracy: 0.7317 - val_loss: 0.5732\n",
            "Epoch 68/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7663 - loss: 0.4539 - val_accuracy: 0.7317 - val_loss: 0.5738\n",
            "Epoch 69/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7782 - loss: 0.4668 - val_accuracy: 0.7317 - val_loss: 0.5732\n",
            "Epoch 70/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7805 - loss: 0.4517 - val_accuracy: 0.7317 - val_loss: 0.5738\n",
            "Epoch 71/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7618 - loss: 0.4745 - val_accuracy: 0.7317 - val_loss: 0.5735\n",
            "Epoch 72/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7873 - loss: 0.4338 - val_accuracy: 0.7317 - val_loss: 0.5741\n",
            "Epoch 73/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7490 - loss: 0.4753 - val_accuracy: 0.7236 - val_loss: 0.5743\n",
            "Epoch 74/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.4416 - val_accuracy: 0.7317 - val_loss: 0.5746\n",
            "Epoch 75/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8059 - loss: 0.4158 - val_accuracy: 0.7317 - val_loss: 0.5753\n",
            "Epoch 76/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.4173 - val_accuracy: 0.7317 - val_loss: 0.5743\n",
            "Epoch 77/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7773 - loss: 0.4390 - val_accuracy: 0.7236 - val_loss: 0.5737\n",
            "Epoch 78/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4900 - val_accuracy: 0.7236 - val_loss: 0.5721\n",
            "Epoch 79/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7844 - loss: 0.4345 - val_accuracy: 0.7236 - val_loss: 0.5715\n",
            "Epoch 80/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7901 - loss: 0.4536 - val_accuracy: 0.7154 - val_loss: 0.5713\n",
            "Epoch 81/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7673 - loss: 0.4621 - val_accuracy: 0.7236 - val_loss: 0.5713\n",
            "Epoch 82/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7870 - loss: 0.4330 - val_accuracy: 0.7236 - val_loss: 0.5718\n",
            "Epoch 83/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7591 - loss: 0.4814 - val_accuracy: 0.7236 - val_loss: 0.5718\n",
            "Epoch 84/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7519 - loss: 0.4767 - val_accuracy: 0.7236 - val_loss: 0.5712\n",
            "Epoch 85/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7811 - loss: 0.4418 - val_accuracy: 0.7236 - val_loss: 0.5727\n",
            "Epoch 86/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.4549 - val_accuracy: 0.7236 - val_loss: 0.5738\n",
            "Epoch 87/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7766 - loss: 0.4409 - val_accuracy: 0.7154 - val_loss: 0.5741\n",
            "Epoch 88/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7874 - loss: 0.4539 - val_accuracy: 0.7154 - val_loss: 0.5735\n",
            "Epoch 89/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7979 - loss: 0.4559 - val_accuracy: 0.7154 - val_loss: 0.5724\n",
            "Epoch 90/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7940 - loss: 0.4539 - val_accuracy: 0.7154 - val_loss: 0.5721\n",
            "Epoch 91/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7656 - loss: 0.4683 - val_accuracy: 0.7154 - val_loss: 0.5733\n",
            "Epoch 92/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7682 - loss: 0.4659 - val_accuracy: 0.7236 - val_loss: 0.5729\n",
            "Epoch 93/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8031 - loss: 0.4326 - val_accuracy: 0.7317 - val_loss: 0.5727\n",
            "Epoch 94/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7546 - loss: 0.4863 - val_accuracy: 0.7317 - val_loss: 0.5729\n",
            "Epoch 95/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7788 - loss: 0.4408 - val_accuracy: 0.7236 - val_loss: 0.5735\n",
            "Epoch 96/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.4648 - val_accuracy: 0.7154 - val_loss: 0.5725\n",
            "Epoch 97/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7590 - loss: 0.4689 - val_accuracy: 0.7236 - val_loss: 0.5722\n",
            "Epoch 98/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7521 - loss: 0.5095 - val_accuracy: 0.7154 - val_loss: 0.5727\n",
            "Epoch 99/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7904 - loss: 0.4679 - val_accuracy: 0.7236 - val_loss: 0.5717\n",
            "Epoch 100/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7619 - loss: 0.4748 - val_accuracy: 0.7236 - val_loss: 0.5724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training (Early Stopping)"
      ],
      "metadata": {
        "id": "K08MZ9-Yulyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping  # import EarlyStopping callback\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",       # watch validation loss to decide when to stop\n",
        "    patience=10,              # stop if no improvement for 10 consecutive epochs\n",
        "    restore_best_weights=True # roll back to the best model weights\n",
        ")"
      ],
      "metadata": {
        "id": "dO6bh9S3umvW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = model.fit(\n",
        "    X_train, y_train,         # training features and labels\n",
        "    epochs=100,               # maximum number of training iterations\n",
        "    batch_size=32,            # samples processed before model update\n",
        "    validation_split=0.2,     # 20% of training data used for validation\n",
        "    verbose=1,                # show training progress\n",
        "    callbacks=[early_stop]    # stop early if val_loss doesn't improve (patience=10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m5XRKH-upQV",
        "outputId": "27584914-3e57-430a-859c-a2ccafcb5094"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8085 - loss: 0.4385 - val_accuracy: 0.7317 - val_loss: 0.5721\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7982 - loss: 0.4466 - val_accuracy: 0.7317 - val_loss: 0.5722\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.4472 - val_accuracy: 0.7236 - val_loss: 0.5723\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7788 - loss: 0.4691 - val_accuracy: 0.7317 - val_loss: 0.5734\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7867 - loss: 0.4486 - val_accuracy: 0.7236 - val_loss: 0.5731\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7821 - loss: 0.4450 - val_accuracy: 0.7317 - val_loss: 0.5719\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8094 - loss: 0.4407 - val_accuracy: 0.7317 - val_loss: 0.5728\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7831 - loss: 0.4589 - val_accuracy: 0.7317 - val_loss: 0.5721\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8061 - loss: 0.4202 - val_accuracy: 0.7317 - val_loss: 0.5739\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8047 - loss: 0.4405 - val_accuracy: 0.7317 - val_loss: 0.5736\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.4548 - val_accuracy: 0.7317 - val_loss: 0.5731\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7821 - loss: 0.4564 - val_accuracy: 0.7317 - val_loss: 0.5742\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8119 - loss: 0.4175 - val_accuracy: 0.7317 - val_loss: 0.5749\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 0.4749 - val_accuracy: 0.7398 - val_loss: 0.5737\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8121 - loss: 0.4198 - val_accuracy: 0.7398 - val_loss: 0.5746\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7849 - loss: 0.4494 - val_accuracy: 0.7398 - val_loss: 0.5740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating"
      ],
      "metadata": {
        "id": "wlO72kbPuvWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)  # evaluate model on test data (loss & accuracy)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")  # print test accuracy with 4 decimal places"
      ],
      "metadata": {
        "id": "WnmjTqy4ux04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b321ce-3612-4fd5-e1e8-1483e5163b71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7987\n"
          ]
        }
      ]
    }
  ]
}